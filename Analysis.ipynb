{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ff0c64d",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6b9741",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25feba3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Wikidata Lexemes (Rows: 17524).\n",
      "Schema:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17524 entries, 0 to 17523\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   lexemeId  17524 non-null  object\n",
      " 1   lemma     17522 non-null  object\n",
      " 2   image     8024 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 410.8+ KB\n",
      "\n",
      "Loaded Concreteness Ratings (Rows: 39954).\n",
      "Schema:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39954 entries, 0 to 39953\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Word           39953 non-null  object \n",
      " 1   Bigram         39954 non-null  int64  \n",
      " 2   Conc.M         39954 non-null  float64\n",
      " 3   Conc.SD        39954 non-null  float64\n",
      " 4   Unknown        39954 non-null  int64  \n",
      " 5   Total          39954 non-null  int64  \n",
      " 6   Percent_known  39954 non-null  float64\n",
      " 7   SUBTLEX        39954 non-null  int64  \n",
      " 8   Dom_Pos        28707 non-null  object \n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "wikidata_lexemes_loc = './datasets/wikidata-english-lexemes.csv'\n",
    "concreteness_ratings_loc = './datasets/concreteness-ratings-brysbaert-et-al.csv'\n",
    "\n",
    "wikidata_lexemes_df = read_csv(wikidata_lexemes_loc)\n",
    "concreteness_ratings_df = read_csv(concreteness_ratings_loc)\n",
    "\n",
    "print(f'Loaded Wikidata Lexemes (Rows: {wikidata_lexemes_df.shape[0]}).\\nSchema:')\n",
    "wikidata_lexemes_df.info()\n",
    "print(f'\\nLoaded Concreteness Ratings (Rows: {concreteness_ratings_df.shape[0]}).\\nSchema:')\n",
    "concreteness_ratings_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45eb39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Join the two datasets\n",
    "def str_merge(part_string_df, full_string_df, merge_column_1, merge_column_2):\n",
    "    merge_column_lower = 'merge_column_lower'\n",
    "    \n",
    "    part_string_df[merge_column_lower] = part_string_df[merge_column_1].str.lower()\n",
    "    full_string_df[merge_column_lower] = full_string_df[merge_column_2].str.lower()\n",
    "    \n",
    "    pat = '|'.join(r'{}'.format(x) for x in part_string_df[merge_column_lower])\n",
    "    full_string_df['matched_column'] = full_string_df[merge_column_lower].str.extract(r'\\b('+ pat + r')\\b', expand=True)\n",
    "    \n",
    "    merged_dfs = pd.merge(part_string_df, full_string_df, left_on= merge_column_lower, right_on='matched_column').drop([merge_column_lower + '_x',merge_column_lower + '_y','matched_column'],axis=1)\n",
    "    return merged_dfs\n",
    "\n",
    "merged_df = str_merge(concreteness_ratings_df, wikidata_lexemes_df, 'Word', 'lemma')[['lemma', 'Word', 'image', 'Conc.M']]\n",
    "# Tidy up the columns\n",
    "merged_df.columns = ['lemma', 'word', 'image', 'concreteness']\n",
    "merged_df = merged_df[merged_df['word'].notnull()]\n",
    "merged_df['has_image'] = pd.notnull(merged_df['image'])\n",
    "\n",
    "merged_df = merged_df[['has_image', 'concreteness']]\n",
    "\n",
    "print('Dataset after merge:')\n",
    "print(merged_df.shape)\n",
    "print(merged_df)\n",
    "\n",
    "has_image_df = merged_df[merged_df['has_image']].reset_index()\n",
    "no_image_df = merged_df[~merged_df['has_image']].reset_index()\n",
    "\n",
    "random_state = 50\n",
    "sample_size = 1000\n",
    "has_image_sample_df = has_image_df.sample(n=sample_size, random_state=random_state).reset_index()[['concreteness']]\n",
    "no_image_sample_df = no_image_df.sample(n=sample_size, random_state=random_state).reset_index()[['concreteness']]\n",
    "\n",
    "print('Entities that have an image:')\n",
    "print(has_image_df.shape)\n",
    "print(has_image_sample_df)\n",
    "\n",
    "print('Entities that do not have an image:')\n",
    "print(no_image_df.shape)\n",
    "print(no_image_sample_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f247db3e",
   "metadata": {},
   "source": [
    "## Significance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3ae06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.weightstats as ws\n",
    "\n",
    "# Sample size is > 30, and we can know the standard deviation.\n",
    "# Therefore, we will use a Z-Test to test for significance.\n",
    "col1 = ws.DescrStatsW(has_image_sample_df['concreteness'])\n",
    "col2 = ws.DescrStatsW(no_image_sample_df['concreteness'])\n",
    "cm_obj = ws.CompareMeans(col1, col2)\n",
    "zstat, z_pval = cm_obj.ztest_ind(usevar='unequal')\n",
    "print(f'Z-Test Results:\\nstatistic: {zstat}\\np-value: {z_pval}')\n",
    "\n",
    "if z_pval <= 0.05:\n",
    "    print('Z Value is less than 0.05 - Rejecting the null hypothesis and accepting the alternative hypothesis.')\n",
    "else:\n",
    "    print('Z Value is greater than 0.05 - Rejecting the alternative hypothesis and accepting the null hypothesis.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52770bbb",
   "metadata": {},
   "source": [
    "## Visualisations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b6752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "labels = ['Lexemes with an image', 'Lexemes without an image']\n",
    "\n",
    "# 1. Plot the total number of Wikidata nouns that have an image/don't in a pie chart\n",
    "def make_autopct(values):\n",
    "    def my_autopct(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct*total/100.0))\n",
    "        return '{p:.2f}%\\n(n={v:d})'.format(p=pct,v=val)\n",
    "    return my_autopct\n",
    "\n",
    "pie_data = np.array([has_image_df.shape[0], no_image_df.shape[0]])\n",
    "pie_explode = [0, 0.1]\n",
    "\n",
    "plt.figure(1)\n",
    "plt.pie(pie_data, labels = labels, startangle = 90, explode = pie_explode, shadow = True, autopct=make_autopct(pie_data))\n",
    "plt.title('Wikidata noun lexemes overview')\n",
    "plt.show()\n",
    "\n",
    "# 2. The mean of each dataset\n",
    "plt.figure(2)\n",
    "data = [has_image_df['concreteness'].mean(), no_image_df['concreteness'].mean()]\n",
    "plt.bar(labels, data)\n",
    "plt.title('The mean concreteness scores of each population')\n",
    "plt.xlabel('Population')\n",
    "plt.ylabel('Mean Concreteness Score')\n",
    "plt.show()\n",
    "\n",
    "# 3. Plot the distribution of concreteness ratings for both datasets\n",
    "data1 = np.array(has_image_df.round(0)['concreteness'].value_counts().sort_index())\n",
    "data2 = np.array(no_image_df.round(0)['concreteness'].value_counts().sort_index())\n",
    "width = 0.3\n",
    "\n",
    "\n",
    "plt.figure(3)\n",
    "plt.bar([0.85, 1.85, 2.85, 3.85, 4.85], data1, width = width)\n",
    "plt.bar([1.15, 2.15, 3.15, 4.15, 5.15], data2, width=width)\n",
    "plt.title('Concreteness rating distribution in relation to whether a noun has an image or not')\n",
    "plt.xlabel('Concreteness Rating (Rounded)')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(labels)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692cbbe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
